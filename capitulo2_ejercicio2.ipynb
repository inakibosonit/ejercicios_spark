{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder.appName(\"ejercicio2\").getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leer el csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"gs://bosonit_spark/archivos/mnm_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.format(\"csv\")\n",
    "      .option(\"inferSchema\", \"true\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .load(csv_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otras operaciones de agregación como el Max con otro tipo de ordenamiento (descendiente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Count|\n",
      "+-----+------+-----+\n",
      "|   CA| Brown|  100|\n",
      "|   WY| Green|  100|\n",
      "|   NV|   Red|  100|\n",
      "|   TX|   Red|  100|\n",
      "|   CA|   Red|  100|\n",
      "|   UT|   Red|  100|\n",
      "|   WY|  Blue|  100|\n",
      "|   UT|Yellow|  100|\n",
      "|   AZ|Orange|  100|\n",
      "|   CO|   Red|  100|\n",
      "|   TX|Yellow|  100|\n",
      "|   CO| Green|  100|\n",
      "|   NV|   Red|  100|\n",
      "|   CA| Brown|  100|\n",
      "|   UT|Yellow|  100|\n",
      "|   CA|   Red|  100|\n",
      "|   NM| Green|  100|\n",
      "|   NV|   Red|  100|\n",
      "|   WA| Brown|  100|\n",
      "|   NM|Orange|  100|\n",
      "+-----+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(\"*\").orderBy(\"Count\", ascending=False)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|State|Color |max(Count)|\n",
      "+-----+------+----------+\n",
      "|WY   |Green |100       |\n",
      "|NV   |Red   |100       |\n",
      "|UT   |Blue  |100       |\n",
      "|WA   |Orange|100       |\n",
      "|NM   |Green |100       |\n",
      "|CA   |Blue  |100       |\n",
      "|WA   |Red   |100       |\n",
      "|NV   |Brown |100       |\n",
      "|AZ   |Green |100       |\n",
      "|CA   |Red   |100       |\n",
      "|AZ   |Orange|100       |\n",
      "|CO   |Blue  |100       |\n",
      "|NM   |Orange|100       |\n",
      "|NM   |Yellow|100       |\n",
      "|WY   |Orange|100       |\n",
      "|UT   |Yellow|100       |\n",
      "|WY   |Red   |100       |\n",
      "|OR   |Blue  |100       |\n",
      "|NV   |Orange|100       |\n",
      "|AZ   |Yellow|100       |\n",
      "+-----+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total Rows = 60\n"
     ]
    }
   ],
   "source": [
    "count_mnm_df.show(n=20, truncate=False)\n",
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hacer un ejercicio como el “where” de CA que aparece en el libro pero indicando más opciones de estados (p.e. NV, TX, CA, CO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_count_mnm_df = (df.select(\"*\")\n",
    "                       .where((df.State == 'CA') | (df.State == 'NV') | (df.State == 'TX') | (df.State == 'CA') | (df.State == 'CO') )\n",
    "                       .groupBy(\"State\", \"Color\")\n",
    "                       .sum(\"Count\")\n",
    "                       .orderBy(\"sum(Count)\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|CA   |Yellow|100956    |\n",
      "|CA   |Brown |95762     |\n",
      "|TX   |Green |95753     |\n",
      "|TX   |Red   |95404     |\n",
      "|CO   |Yellow|95038     |\n",
      "|NV   |Orange|93929     |\n",
      "|TX   |Yellow|93819     |\n",
      "|CO   |Green |93724     |\n",
      "|CO   |Brown |93692     |\n",
      "|CA   |Green |93505     |\n",
      "+-----+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ca_count_mnm_df.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer un ejercicio donde se calculen en una misma operación el Max, Min, Avg, Count. Revisar el API (documentación) donde encontrarán este ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_df = df.select(F.count(df.Count).alias(\"count\"), F.avg(df.Count).alias(\"promedio\"), F.min(df.Count).alias(\"minimo\"), F.max(df.Count).alias(\"maximo\"))               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+------+------+\n",
      "|count|         promedio|minimo|maximo|\n",
      "+-----+-----------------+------+------+\n",
      "|99999|55.00090000900009|    10|   100|\n",
      "+-----+-----------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "operations_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer también ejercicios en SQL creando tmpView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_df.createOrReplaceTempView(\"calculos_tabla\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
